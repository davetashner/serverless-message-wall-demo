{"type":"epic","id":"EPIC-1","title":"Bootstrap Kubernetes actuator and Crossplane","intent":"Prepare a Kubernetes cluster that acts only as an infrastructure actuator using Crossplane controllers.","principles":["Kubernetes is actuator only","No application runtime in Kubernetes"],"status":"done"}
{"type":"issue","epic":"EPIC-1","id":"ISSUE-1.0","title":"Create AWS IAM resources for Crossplane","description":"Create the permission boundary policy and crossplane-actuator IAM user per ADR-006. This is a manual prerequisite before Crossplane can manage AWS resources.","acceptance":["MessageWallRoleBoundary policy exists in AWS","crossplane-actuator IAM user exists with scoped policy","User policy requires permission boundary on created roles","Access keys generated and stored securely"],"status":"done"}
{"type":"issue","epic":"EPIC-1","id":"ISSUE-1.1","title":"Create local actuator cluster","description":"Provision a local Kubernetes cluster (kind) for running Crossplane.","acceptance":["Cluster reachable via kubectl","Idempotent bootstrap script exists","Cluster named 'actuator'"],"status":"done"}
{"type":"issue","epic":"EPIC-1","id":"ISSUE-1.2","title":"Install Crossplane via Helm","description":"Install Crossplane into the actuator cluster using Helm per ADR-006.","acceptance":["Crossplane pods running in crossplane-system namespace","Installation is idempotent","Helm release named 'crossplane'"],"status":"done"}
{"type":"issue","epic":"EPIC-1","id":"ISSUE-1.3","title":"Install AWS Crossplane family providers","description":"Install AWS family providers (s3, dynamodb, lambda, cloudwatchevents, iam) and configure ProviderConfig with crossplane-actuator credentials per ADR-006.","acceptance":["All five AWS family providers healthy","ProviderConfig references Kubernetes Secret with crossplane-actuator credentials","Providers configured for us-east-1","Able to create test AWS resource with messagewall-* prefix"],"status":"done"}
{"type":"issue","epic":"EPIC-1","id":"ISSUE-1.4","title":"Install Kyverno","description":"Install Kyverno policy engine into the actuator cluster per ADR-007.","acceptance":["Kyverno pods running in kyverno namespace","Installation is idempotent","Kyverno admission webhooks registered"],"status":"done"}
{"type":"issue","epic":"EPIC-1","id":"ISSUE-1.5","title":"Create Kyverno mutation policy for AWS resource tags","description":"Create ClusterPolicy that automatically adds required tags (createdBy, managedBy, environment) to all AWS managed resources per ADR-007.","acceptance":["Policy applies to S3, DynamoDB, Lambda, CloudWatchEvents resources","Tags createdBy=crossplane, managedBy=messagewall-demo, environment=dev added automatically","Policy is mutating (adds tags if missing)"],"status":"done"}
{"type":"issue","epic":"EPIC-1","id":"ISSUE-1.6","title":"Create Kyverno validation policy for AWS resource tags","description":"Create ClusterPolicy that rejects AWS managed resources missing required tags per ADR-007.","acceptance":["Policy applies to S3, DynamoDB, Lambda, CloudWatchEvents resources","Resources without required tags are rejected","Policy runs in Enforce mode","Clear error message on rejection"],"status":"done"}
{"type":"epic","id":"EPIC-2","title":"Define core AWS infrastructure resources","intent":"Provision the AWS resources required to run the serverless application using Crossplane-managed resources.","status":"done"}
{"type":"issue","epic":"EPIC-2","id":"ISSUE-2.1","title":"Create S3 bucket for static site and state","description":"Provision an S3 bucket in us-east-1 for hosting static web assets, state.json, and Lambda artifacts.","acceptance":["Bucket named messagewall-* exists in us-east-1","S3 static website hosting enabled","Website endpoint accessible","Bucket policy allows public read for web content","Bucket supports artifacts/ prefix for Lambda ZIPs"],"status":"done"}
{"type":"issue","epic":"EPIC-2","id":"ISSUE-2.2","title":"Create DynamoDB table","description":"Provision DynamoDB table using single-table design per ADR-004.","acceptance":["Table named messagewall-* exists in us-east-1","Partition key: PK (String)","Sort key: SK (String)","Table accessible from Lambda","Supports METADATA and MESSAGE record types"],"status":"done"}
{"type":"issue","epic":"EPIC-2","id":"ISSUE-2.3","title":"Create IAM roles and policies for Lambda","description":"Define least-privilege IAM roles for Lambda functions. Roles must have MessageWallRoleBoundary attached per ADR-006.","acceptance":["Separate roles: messagewall-api-role and messagewall-snapshot-role","Both roles have MessageWallRoleBoundary permission boundary","api-handler role: DynamoDB read/write, EventBridge PutEvents, CloudWatch Logs","snapshot-writer role: DynamoDB read, S3 PutObject, CloudWatch Logs"],"status":"done"}
{"type":"epic","id":"EPIC-3","title":"Implement Lambda functions","intent":"Create minimal Lambda functions that implement the application behavior.","status":"done"}
{"type":"issue","epic":"EPIC-3","id":"ISSUE-3.1","title":"Implement api-handler Lambda","description":"Create Lambda that handles browser requests, updates DynamoDB, and emits EventBridge events.","acceptance":["POST increments messageCount in METADATA record","POST stores message with PK=MESSAGE, SK=timestamp#uuid","EventBridge event emitted to default bus","Logs visible in CloudWatch","Returns CORS headers"],"status":"done"}
{"type":"issue","epic":"EPIC-3","id":"ISSUE-3.2","title":"Implement snapshot-writer Lambda","description":"Create Lambda that generates state.json from DynamoDB and writes it to S3.","acceptance":["Reads messageCount from METADATA record","Queries last 5 messages ordered by SK descending","Writes valid JSON to s3://messagewall-*/state.json","Overwrites previous snapshot safely"],"status":"done"}
{"type":"issue","epic":"EPIC-3","id":"ISSUE-3.3","title":"Package Lambda artifacts","description":"Produce deterministic ZIP artifacts for both Lambdas.","acceptance":["Repeatable build scripts exist","Artifacts uploaded to s3://messagewall-*/artifacts/","api-handler.zip and snapshot-writer.zip produced","Crossplane manifests reference S3 artifact locations"],"status":"done"}
{"type":"epic","id":"EPIC-4","title":"Wire event-driven flow","intent":"Connect AWS services so changes propagate via events, not direct coupling.","status":"done"}
{"type":"issue","epic":"EPIC-4","id":"ISSUE-4.1","title":"Expose api-handler via Lambda Function URL","description":"Create a Lambda Function URL to accept browser requests.","acceptance":["URL reachable from browser","CORS configured for S3 website origin","POST requests invoke Lambda","AUTH_TYPE set to NONE for public access"],"status":"done"}
{"type":"issue","epic":"EPIC-4","id":"ISSUE-4.2","title":"Create EventBridge rule for snapshot updates","description":"Trigger snapshot-writer Lambda on api-handler events.","acceptance":["Rule named messagewall-* on default EventBridge bus","Rule matches events from api-handler","snapshot-writer invoked successfully on match"],"status":"done"}
{"type":"epic","id":"EPIC-5","title":"Create browser-based UI","intent":"Provide a simple browser experience that makes the application easy to reason about.","status":"done"}
{"type":"issue","epic":"EPIC-5","id":"ISSUE-5.1","title":"Create static HTML page","description":"Create index.html for displaying message count and messages.","acceptance":["Page loads from S3 website endpoint","UI shows message count","UI shows list of recent messages","UI has text input and Post button"],"status":"done"}
{"type":"issue","epic":"EPIC-5","id":"ISSUE-5.2","title":"Implement browser-side JavaScript","description":"Fetch state.json and POST messages to Lambda Function URL.","acceptance":["Fetches state.json on page load","Renders message count and messages","POST sends message text to Lambda Function URL","UI updates on page refresh after posting"],"status":"done"}
{"type":"epic","id":"EPIC-6","title":"Demo scripts and verification","intent":"Make the demo easy to deploy, verify, and clean up.","status":"done"}
{"type":"issue","epic":"EPIC-6","id":"ISSUE-6.1","title":"Create deployment script","description":"Script that applies all Crossplane resources for a dev environment.","acceptance":["Single command deploys full stack","Script is idempotent","Waits for resources to be ready"],"status":"done"}
{"type":"issue","epic":"EPIC-6","id":"ISSUE-6.2","title":"Create smoke test","description":"Script that posts a message and verifies DynamoDB and S3 state.","acceptance":["Script posts a test message via Lambda Function URL","Verifies state.json updated in S3","Verifies DynamoDB contains the message","Reports success or failure clearly"],"status":"done"}
{"type":"issue","epic":"EPIC-6","id":"ISSUE-6.3","title":"Create cleanup script","description":"Script that tears down all managed resources.","acceptance":["Deletes Crossplane-managed AWS resources","Empties S3 bucket before deletion","Repeated runs succeed without error"],"status":"done"}
{"type":"epic","id":"EPIC-7","title":"Prepare for platform extensions","intent":"Lay groundwork for future demos involving ConfigHub, bulk changes, and policy enforcement.","status":"done"}
{"type":"issue","epic":"EPIC-7","id":"ISSUE-7.1","title":"Document bulk change scenarios","description":"Describe how Lambda memory/timeouts could be changed across environments.","acceptance":["README includes bulk-change walkthrough"],"status":"done"}
{"type":"issue","epic":"EPIC-7","id":"ISSUE-7.2","title":"Document ConfigHub integration points","description":"Identify where ConfigHub could manage and mutate resolved configuration.","acceptance":["Clear narrative for ConfigHub + Crossplane demo","References ADR-005"],"status":"done"}
{"type":"epic","id":"EPIC-8","title":"Integrate ConfigHub as configuration control plane","intent":"Establish ConfigHub as the authoritative store for fully-rendered Crossplane manifests. Flow: Git (authoring) -> Render CRDs (CI) -> ConfigHub (authoritative) -> Kubernetes actuator. See ADR-005.","principles":["ConfigHub is authoritative for resolved config","Git remains authoring surface","Crossplane remains actuator","No direct kubectl apply from CI for managed resources"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.1","title":"Define ConfigHub spaces and units for the demo","description":"Create ConfigHub spaces and initial units representing the serverless application infrastructure.","acceptance":["ConfigHub space exists for demo","Units correspond to Lambda, DynamoDB, S3, EventBridge resources","Units are environment-scoped (e.g., dev)"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.2","title":"Render and publish Crossplane manifests to ConfigHub","description":"Create CI pipeline step that renders fully-resolved Crossplane manifests and publishes to ConfigHub.","acceptance":["Rendered manifests have no placeholders or variables","Manifests published to ConfigHub via API","ConfigHub holds authoritative resolved config"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.3","title":"Attach policy checks to ConfigHub units","description":"Define and apply policy checks (OPA or ConfigHub functions) to enforce basic guardrails.","acceptance":["Policy blocks overly permissive IAM policies","Policy enforces minimum Lambda timeout/memory","Policy runs before actuation"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.4","title":"Clarify and implement ConfigHub actuation mechanism","description":"Determine how ConfigHub-approved manifests reach the Kubernetes actuator (ArgoCD push vs actuator pull) and implement the chosen approach.","acceptance":["Actuation mechanism documented","ConfigHub-approved config reaches actuator cluster","No direct kubectl apply from CI","Status is observable in both ConfigHub and Kubernetes"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.5","title":"Demonstrate bulk configuration change via ConfigHub","description":"Use a ConfigHub function to update configuration across multiple resources in one operation.","acceptance":["Single operation updates both Lambda functions","Change reflected in AWS","Change visible as a single ConfigHub revision"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.6","title":"Demonstrate controlled rollout of ConfigHub revisions","description":"Show how revisions from multiple sources (CI, bulk changes, break-glass) accumulate in ConfigHub, and how deployment to the actuator is controlled separately from revision creation. ConfigHub distinguishes HeadRevisionNum (latest) from LiveRevisionNum (deployed). The key insight: 'cub unit update' creates revisions, 'cub unit apply' deploys them - these are separate operations. Implementation: (1) Verify if current CI/worker auto-applies revisions, (2) If so, add an approval gate so revisions require explicit promotion, (3) Create demo showing operator choosing which revision to deploy.","acceptance":["Verify whether CI or worker currently auto-applies revisions to actuator","If auto-apply exists, add approval gate requiring explicit 'cub unit apply'","Demo shows HeadRevisionNum diverging from LiveRevisionNum after CI push","Operator can review pending revisions and choose which to deploy","Demo script (e.g., scripts/demo-revision-rollout.sh) walks through controlled promotion"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.7","title":"Demonstrate break-glass recovery and reconciliation","description":"Show how a direct AWS-side change can be reconciled back into ConfigHub after recovery.","acceptance":["Emergency change captured","ConfigHub reconciles new state","Audit trail preserved"],"status":"done"}
{"type":"issue","epic":"EPIC-8","id":"ISSUE-8.8","title":"Document ConfigHub + Crossplane demo narrative","description":"Create a clear walkthrough explaining how ConfigHub, Crossplane, and AWS interact in the demo.","acceptance":["README explains control flow per ADR-005","Demo highlights risk reduction and operability gains","Narrative is understandable without prior ConfigHub knowledge"],"status":"done"}
{"type":"epic","id":"EPIC-9","title":"Setup wizard for new users","intent":"Enable new users to configure and deploy the demo with their own AWS account through an interactive setup wizard. The wizard handles all environment-specific values (AWS account ID, S3 bucket name, region) and guides users through the full deployment process.","principles":["Works reliably across different machines","Fails fast with clear error messages","Supports both interactive and scripted usage","POSIX sh for maximum portability"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.1","title":"Write ADR-008 for setup wizard design","description":"Document the design decisions for the setup wizard including interaction modes, validation strategy, template approach, and two-phase deployment for Function URL.","acceptance":["ADR-008 exists in docs/decisions/","Documents interactive vs non-interactive modes","Documents placeholder syntax (__PLACEHOLDER__)","Documents two-phase deployment for Function URL","Documents POSIX sh choice for portability"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.2","title":"Convert hardcoded values to placeholders","description":"Replace all environment-specific hardcoded values with placeholder syntax. Affected files: IAM policies, Crossplane manifests, deploy scripts, Lambda defaults, index.html.","acceptance":["All AWS account IDs replaced with __AWS_ACCOUNT_ID__","All bucket/table names replaced with __RESOURCE_PREFIX__","All regions replaced with __AWS_REGION__","Function URL in index.html replaced with __FUNCTION_URL__","Placeholder syntax is consistent across all files","List of all placeholder locations documented"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.3","title":"Create setup wizard with interactive mode","description":"Create scripts/setup.sh that prompts users for required values: AWS account ID, resource prefix (for S3/DynamoDB naming), and AWS region.","acceptance":["Wizard prompts for each required value","Clear descriptions explain what each value is for","Prompts show example/default values","User can accept defaults by pressing Enter","Wizard summarizes inputs before applying"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.4","title":"Add non-interactive mode with CLI flags","description":"Support --non-interactive mode with explicit flags: --account-id, --resource-prefix, --region. All values required in non-interactive mode.","acceptance":["--non-interactive flag disables prompts","--account-id=VALUE sets AWS account ID","--resource-prefix=VALUE sets S3/DynamoDB prefix","--region=VALUE sets AWS region","Missing required values in non-interactive mode cause clear error","--help shows all available flags"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.5","title":"Implement input validation","description":"Validate user inputs before patching files. Check format only (no AWS API calls).","acceptance":["AWS account ID must be exactly 12 digits","Resource prefix must be valid for S3 bucket names (lowercase, no underscores, 3-37 chars)","Region must match AWS region format (e.g., us-east-1)","Invalid inputs show clear error message with expected format","Validation errors do not modify any files"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.6","title":"Implement re-run detection and warning","description":"Detect if the wizard has already been run (placeholders already replaced) and warn the user before overwriting.","acceptance":["Wizard detects if files contain placeholders or real values","If already configured, warns user and shows current values","User must confirm to overwrite (--force flag in non-interactive)","Provides option to abort without changes"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.7","title":"Add dry-run mode","description":"Support --dry-run flag that shows what would change without modifying files.","acceptance":["--dry-run flag prevents all file modifications","Shows diff-style output for each file that would change","Shows summary of total files affected","Exit code 0 if dry-run succeeds"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.8","title":"Create AWS validation command","description":"Create scripts/validate-aws.sh that checks AWS credentials, permissions, and resource availability.","acceptance":["Checks AWS CLI is installed and configured","Checks caller identity matches provided account ID","Checks S3 bucket name is available (not taken)","Checks IAM permissions for creating required resources","Reports clear pass/fail for each check","Suggests fixes for common failures"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.9","title":"Handle Function URL finalization","description":"After infrastructure deployment, the Function URL is generated by AWS. Create a finalize step that retrieves the URL and updates index.html.","acceptance":["scripts/finalize-setup.sh retrieves Function URL from kubectl","Updates index.html with actual Function URL","Re-uploads index.html to S3","Works after deploy-dev.sh completes","Clear error if Function URL not yet available"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.10","title":"Integrate with bootstrap scripts","description":"After configuration, offer to run the full bootstrap and deployment sequence.","acceptance":["Wizard offers to run bootstrap after configuration","User can skip and run manually later","If user accepts, runs: bootstrap-kind.sh, bootstrap-crossplane.sh, bootstrap-aws-providers.sh, bootstrap-kyverno.sh","Each phase shows progress and waits for completion","On failure, stops and shows which phase failed"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.11","title":"Create test suite for wizard","description":"Write tests for the setup wizard covering validation, placeholder replacement, and error handling.","acceptance":["Tests for input validation functions","Tests for placeholder replacement logic","Tests for re-run detection","Tests for dry-run mode","Tests run in CI without AWS credentials","Test framework documented in CONTRIBUTING.md or test README"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.12","title":"Write integration test for full setup flow","description":"Create an end-to-end test that runs the wizard in non-interactive mode and verifies all placeholders are replaced correctly.","acceptance":["Test runs wizard with known inputs","Verifies all placeholders replaced in all files","Verifies no placeholders remain","Can run without AWS credentials (file changes only)","Documents how to run integration tests"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.13","title":"Update getting started documentation","description":"Rewrite docs/setup-actuator-cluster.md and README.md to use the setup wizard as the primary onboarding path.","acceptance":["README quick start uses setup wizard","docs/setup-actuator-cluster.md updated with wizard instructions","Manual setup steps still documented as alternative","Troubleshooting section for common wizard issues","Screenshots or terminal output examples included"],"status":"done"}
{"type":"issue","epic":"EPIC-9","id":"ISSUE-9.14","title":"Add prerequisite checker","description":"Check that required tools are installed before running the wizard: aws cli, kubectl, kind, helm, docker.","acceptance":["Checks each required tool is installed","Shows version of each tool found","Suggests installation commands for missing tools (brew, apt, etc.)","Can be run standalone: scripts/check-prerequisites.sh","Wizard runs this automatically at start"],"status":"done"}
{"type":"epic","id":"EPIC-10","title":"Stabilize mental model and plane separation","intent":"Establish and document a clear separation between intent, authority, actuation, and runtime so subsequent work does not mix concerns or introduce accidental complexity.","principles":["Explicit planes","Single responsibility per artifact","Documentation as a forcing function"],"status":"done"}
{"type":"issue","epic":"EPIC-10","id":"ISSUE-10.1","title":"Document the four-plane model for the platform","description":"Write a concise document defining the Intent, Authority, Actuation, and Runtime planes and mapping existing artifacts in the repo to each plane.","acceptance":["Document exists under docs/planes.md","Each plane has a one-paragraph definition","Every major repo artifact is assigned to exactly one plane"],"status":"done"}
{"type":"issue","epic":"EPIC-10","id":"ISSUE-10.2","title":"Define platform invariants and non-goals","description":"Explicitly document invariants (e.g., Kubernetes is actuator-only, no app runtime in cluster) and non-goals to guide future design decisions.","acceptance":["Invariants documented under docs/invariants.md","Non-goals documented and time-boxed","Invariants referenced by later epics"],"status":"done"}
{"type":"epic","id":"EPIC-11","title":"Introduce a single platform product via Crossplane XRD","intent":"Collapse the existing infrastructure into a single developer-facing product boundary using a Crossplane Composite Resource.","principles":["One product, one claim","Hide AWS wiring","Small stable v1 schema"],"status":"paused"}
{"type":"issue","epic":"EPIC-11","id":"ISSUE-11.1","title":"Design minimal v1 schema for ServerlessEventApp XRD","description":"Define a minimal Crossplane XRD schema that captures the message-wall application shape without exposing AWS or IAM primitives. Schema should be only as complex as needed to fully produce the message wall demo infrastructure, while maintaining the ability to reuse the serverless event-driven application pattern for similar apps. Avoid over-abstraction.","acceptance":["XRD schema defined with <=10 fields for the demo use case","Fields represent intent (not infrastructure)","Defaults provided for non-essential fields","Schema is extensible for future event-driven apps without breaking changes","No AWS-specific concepts exposed to developers"],"status":"paused"}
{"type":"issue","epic":"EPIC-11","id":"ISSUE-11.2","title":"Implement Composition for ServerlessEventApp","description":"Create a Crossplane Composition that expands the XRD into all required AWS managed resources for the message wall.","acceptance":["Composition renders S3, DynamoDB, IAM, Lambda, and EventBridge","Single Claim produces a working application","Resources reach Ready state without manual intervention"],"status":"paused"}
{"type":"issue","epic":"EPIC-11","id":"ISSUE-11.3","title":"Replace raw managed resources with a single Claim","description":"Refactor the deployment so environments are created by applying a single Claim rather than multiple managed resources.","acceptance":["dev environment deploys from one Claim","No direct application of managed AWS resources remains","Existing functionality preserved"],"status":"paused"}
{"type":"issue","epic":"EPIC-11","id":"ISSUE-11.4","title":"Define XRD status fields and connection details","description":"Configure the XRD to expose key outputs as status fields so developers and automation can discover endpoints and observe readiness. The Function URL is generated by AWS after Lambda creation and must be surfaced.","acceptance":["websiteEndpoint exposed as status field","apiEndpoint (Function URL) exposed as status field","Aggregate Ready condition reflects all child resources","Meaningful error messages propagated from failed child resources","Status fields are queryable via kubectl and usable by ConfigHub"],"status":"paused"}
{"type":"issue","epic":"EPIC-11","id":"ISSUE-11.5","title":"Create test suite for ServerlessEventApp Composition","description":"Validate that the Composition correctly expands Claims into working infrastructure.","acceptance":["Unit test: Composition renders expected managed resources from a sample Claim","Integration test: Applied Claim reaches Ready state in actuator cluster","Smoke test: Post a message via apiEndpoint, verify it appears in state.json via websiteEndpoint","Tests documented and runnable via scripts/test-xrd.sh or similar"],"status":"paused"}
{"type":"issue","epic":"EPIC-11","id":"ISSUE-11.6","title":"Document ServerlessEventApp schema for developers","description":"Provide clear documentation so developers understand what fields are available, what values are valid, and how to troubleshoot.","acceptance":["Field descriptions with valid values and defaults documented","Example Claims for dev and prod environments","Troubleshooting guide for common status conditions (not ready, sync failed, etc.)","Documentation lives in docs/ or alongside XRD definition"],"status":"done"}
{"type":"issue","epic":"EPIC-11","id":"ISSUE-11.7","title":"Decide what ConfigHub stores (Claim vs expanded resources)","description":"Clarify whether ConfigHub holds the developer-authored Claim or the fully-expanded managed resources. This decision affects authority boundaries, diff visibility, and bulk change mechanics.","acceptance":["Decision documented with rationale in ADR or design doc","Trade-offs of each approach enumerated","Decision aligns with EPIC-13 configuration authority goals","ADR-005 updated if needed to reflect decision"],"status":"done"}
{"type":"epic","id":"EPIC-12","title":"Establish schema-first developer authoring experience","intent":"Merged into EPIC-16. Original intent: Decide and validate what developers author directly, ensuring they never need to reason about AWS wiring or Crossplane internals.","principles":["Developers author intent only","Schema constrains possibility space","Fast feedback on invalid inputs"],"status":"done","note":"Merged into EPIC-16"}
{"type":"epic","id":"EPIC-13","title":"Introduce configuration authority via ConfigHub","intent":"Make configuration authoritative outside of Git and prevent accidental overwrites or clobbering during iteration and bulk change.","principles":["Single source of truth","Bulk change safety","Explicit ownership"],"status":"done"}
{"type":"issue","epic":"EPIC-13","id":"ISSUE-13.1","title":"Model ServerlessEventApp config as ConfigHub units","description":"Represent the developer-facing config (Claim or higher-level spec) as a ConfigHub unit with versioning and history.","acceptance":["ConfigHub unit created for the app","Unit represents full desired configuration","ConfigHub history reflects changes over time"],"status":"done","note":"Completed as part of EPIC-8 and EPIC-11. ConfigHub stores ServerlessEventAppClaims per ADR-010."}
{"type":"issue","epic":"EPIC-13","id":"ISSUE-13.2","title":"Wire ConfigHub apply flow to Crossplane actuator","description":"Create a delivery path where approved ConfigHub config is rendered and applied to the actuator cluster.","acceptance":["ConfigHub-driven change results in updated AWS resources","No direct kubectl apply from CI","Apply status is observable"],"status":"done","note":"Completed as part of EPIC-8. ArgoCD CMP plugin syncs from ConfigHub per ADR-009."}
{"type":"issue","epic":"EPIC-13","id":"ISSUE-13.3","title":"Implement bidirectional sync between Git and ConfigHub","description":"Per ADR-011, implement the three-way sync model where ConfigHub is authoritative and changes flow bidirectionally. Phase 1: ConfigHub → Git sync (visibility). Phase 2: Git → ConfigHub as proposal (conflict prevention). Phase 3: Live → ConfigHub capture (break-glass safety). Start with Phase 1 as it provides immediate value and unblocks the mental model.","acceptance":["ConfigHub changes trigger sync back to Git (Phase 1)","CI cannot silently overwrite ConfigHub changes (Phase 2)","Break-glass changes are captured, not lost (Phase 3)","Conflict resolution process documented"],"status":"done","note":"Implemented all three phases: Phase 1 (sync-confighub-to-git.sh + workflow), Phase 2 (updated confighub-publish.yml with conflict detection), Phase 3 (capture-drift-to-confighub.sh). Documentation in docs/bidirectional-sync.md."}
{"type":"issue","epic":"EPIC-13","id":"ISSUE-13.4","title":"Create Mermaid architecture diagram for ConfigHub-to-AWS flow","description":"Create a clear Mermaid diagram showing the complete flow from developer authoring through ConfigHub authority to AWS resource actuation. Diagram should show Git, CI, ConfigHub, ArgoCD, Kubernetes, Crossplane, and AWS components with their relationships.","acceptance":["Mermaid diagram exists in docs/","Diagram shows all components: Git, CI, ConfigHub, ArgoCD, Kubernetes, Crossplane, AWS","Flow direction and relationships are clear","Diagram renders correctly in GitHub markdown","Referenced from relevant ADRs or architecture docs"],"status":"done"}
{"type":"issue","epic":"EPIC-13","id":"ISSUE-13.5","title":"Write ADR-011: Bidirectional GitOps with ConfigHub as Authority","description":"ConfigHub is the authoritative source for configuration, but CI currently publishes rendered Claims from Git. This creates a conflict: bulk changes made in ConfigHub can be overwritten by subsequent CI runs. Write an ADR exploring approaches to resolve this while preserving ConfigHub as the authority.","acceptance":["ADR-011 exists in docs/decisions/","Problem statement clearly describes the CI vs ConfigHub conflict","At least 3 approaches evaluated with trade-offs","Decision preserves ConfigHub as authoritative source","Decision addresses how Git/CI role changes (if at all)","Implementation path is clear enough to unblock ISSUE-13.3"],"status":"done","note":"ADR-011 written. Reframed as bidirectional GitOps with three-way sync model. Open questions remain for implementation details."}
{"type":"epic","id":"EPIC-14","title":"Add minimal policy guardrails","intent":"Introduce a small set of high-value policies that prevent dangerous configurations before actuation. Policies run at multiple enforcement points: ConfigHub (authority layer), Kyverno (actuator cluster), and optionally CI/pre-commit for fast feedback.","principles":["Fail fast","Few policies, high leverage","Policy before deployment","Defense in depth (multiple enforcement points)"],"status":"done"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.0","title":"Document policy enforcement architecture (OPA at multiple layers)","description":"Document that OPA policies run at multiple enforcement points: (1) ConfigHub (authority layer, before apply), (2) Kyverno in actuator cluster (runtime layer, admission control), (3) optionally CI/pre-commit for early feedback. Update existing docs (ADR-005, planes.md, architecture-flow.md) to reflect this defense-in-depth approach.","acceptance":["Policy enforcement points documented in architecture docs","ADR-005 updated to mention multi-layer enforcement","planes.md updated to show policy as cross-cutting concern","Clear explanation of why policies run in multiple places (defense in depth, fail fast)"],"status":"done"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.1","title":"Add policy to block wildcard IAM permissions","description":"Implement a policy that prevents wildcard actions or resources in IAM permissions derived from the platform schema.","acceptance":["Policy fails on wildcard permissions","Clear human-readable error message","Passing example documented"],"status":"done","note":"Implemented in platform/kyverno/policies/validate-iam-no-wildcards.yaml"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.2","title":"Add bounds on Lambda memory and timeout","description":"Enforce reasonable upper and lower bounds on Lambda memory and timeout settings.","acceptance":["Out-of-bounds values are rejected","Bounds are configurable by platform team","Policy evaluated before apply"],"status":"done","note":"Implemented in platform/kyverno/policies/validate-claim-prod-requirements.yaml with env-specific bounds"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.3","title":"Duplicate required tags policy in ConfigHub","description":"The Kyverno tag mutation/validation policies (ISSUE-1.5, 1.6) enforce tags at the actuator layer. Duplicate this policy in ConfigHub so tags are validated before actuation, demonstrating defense-in-depth.","acceptance":["ConfigHub policy requires createdBy, managedBy, environment tags","Policy runs before apply in ConfigHub","Violations surface in ConfigHub UI/API with clear message","Documents why same policy exists in both ConfigHub and Kyverno"],"status":"done","note":"Implemented in platform/confighub/policies/require-tags.rego with README explaining defense-in-depth"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.4","title":"Add encryption at rest policy","description":"Require encryption at rest for stateful resources (S3, DynamoDB) in production environments.","acceptance":["Policy requires S3 bucket encryption for prod Claims","Policy requires DynamoDB encryption for prod Claims","Dev environments may have relaxed requirements","Clear error message on violation"],"status":"done","note":"Implemented in platform/kyverno/policies/validate-encryption-at-rest.yaml"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.5","title":"Add environment-specific policy constraints","description":"Enforce different policy thresholds based on environment (dev vs prod). Examples: prod requires Lambda memory >= 256MB, prod requires DynamoDB point-in-time recovery, prod requires S3 versioning enabled.","acceptance":["Policies differentiate between dev and prod environments","Prod Lambda memory minimum: 256MB","Prod Lambda timeout minimum: 30s","Prod DynamoDB: point-in-time recovery required","Prod S3: versioning required","Dev environments have relaxed constraints","Policy configuration is maintainable (not hardcoded per-environment)"],"status":"done","note":"Implemented across validate-claim-prod-requirements.yaml and validate-encryption-at-rest.yaml"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.6","title":"Document policy guardrails demo narrative","description":"Create a clear walkthrough showing how policies prevent dangerous configurations at multiple layers. Include examples of policy violations and how they surface to developers/operators.","acceptance":["Demo script or guide exists","Shows policy violation in ConfigHub (pre-apply)","Shows policy violation in Kyverno (admission)","Explains defense-in-depth value","Understandable without deep OPA knowledge"],"status":"done","note":"Created docs/demo-policy-guardrails.md with three demo scenarios and policy summary"}
{"type":"issue","epic":"EPIC-14","id":"ISSUE-14.7","title":"Design policy-to-risk-class mapping for EPIC-15 integration","description":"Document how EPIC-14 policies connect to EPIC-15 risk classes. Policies can enforce risk-based constraints: low-risk changes pass automatically, medium-risk changes require policy validation, high-risk changes require policy validation + human approval. This design doc bridges policy enforcement (EPIC-14) with agent-human boundaries (EPIC-15).","acceptance":["Design doc maps each policy to risk class(es) it enforces","Document explains how policy violations escalate to approval workflows","Clear boundary between policy enforcement (automated) and approval gates (human)","Design is reviewed before implementing EPIC-15 approval workflows","References ISSUE-15.1 (risk class definitions)"],"status":"done","note":"Created docs/design-policy-risk-class-mapping.md with risk classes, policy mapping, escalation model, and automation/human boundary"}
{"type":"epic","id":"EPIC-15","title":"Define agent–human change boundaries","intent":"Establish risk taxonomy and approval workflows for AI-assisted configuration changes. Defines how agents propose changes, how risk is classified, and when human approval is required. Focuses on the conceptual model and forward-looking agent considerations.","principles":["Agents propose, humans decide","Explicit risk classes","No silent privilege expansion"],"status":"done"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.1","title":"Define risk classes for configuration changes","description":"Classify configuration changes into low, medium, and high risk based on blast radius and reversibility.","acceptance":["Risk taxonomy documented","Each schema field mapped to a risk class","Taxonomy reviewed against real examples"],"depends_on":"ISSUE-14.7","status":"done","note":"Created docs/risk-taxonomy.md with formal risk class definitions, schema field mapping, context elevators, and validation against real Claims"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.2","title":"Implement agent proposal workflow","description":"Create a workflow where an agent proposes config changes as a patch or changeset without applying them.","acceptance":["Agent produces a valid proposed change","Proposal is reviewable by a human","Proposal cannot be applied directly"],"status":"done","note":"Created docs/design-agent-proposal-workflow.md with proposal schema, lifecycle, storage options, and review interface"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.3","title":"Require human approval for high-risk changes","description":"Introduce an explicit approval mechanism that gates application of high-risk changes.","acceptance":["High-risk changes blocked without approval","Low-risk changes can be applied without approval","Approval path documented"],"status":"done","note":"Created docs/design-approval-gates.md with approval requirements by risk class, approver roles, blocking behavior, and PR-based implementation"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.13","title":"Document risks of approval fatigue and approval theater","description":"Capture the risk that human approvals become rubber-stamping as agent proposal volume increases, and outline mitigations.","acceptance":["Failure mode described with concrete examples","Mitigations proposed (risk aggregation, confidence thresholds, automation)","Document explicitly states when human approval alone is insufficient"],"status":"done","note":"Created docs/approval-fatigue-and-theater.md with 5 failure modes, 8 mitigations, and clear criteria for when human approval is insufficient"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.14","title":"Explore machine-verifiable invariants as complements to human approval","description":"Investigate how formal invariants, policies, or safety envelopes could allow agents to approve other agents within strict bounds.","acceptance":["List of candidate invariants documented","Examples show invariants preventing irreversible harm","Clear boundary defined between invariant enforcement and human judgment"],"status":"done","note":"Created docs/machine-verifiable-invariants.md with 5 invariant categories, 3 harm-prevention examples, and clear invariant vs human judgment boundary"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.15","title":"Assess schema evolution pressure from intelligent agent behavior","description":"Analyze how increasingly capable agents may stress or bypass schema-first design, and how extension points or versioning could mitigate this.","acceptance":["Schema growth risks documented","Proposed extension/escape-hatch strategy outlined","Guidelines defined for promoting extensions to core schema"],"status":"done","note":"Created docs/schema-evolution-pressure.md with 5 schema risks, 4 extension strategies, escape hatch design, and promotion guidelines"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.17","title":"Explore feedback loops from runtime signals back into configuration authority","description":"Investigate how runtime observations (health, drift, learned behavior) could inform or update authoritative configuration without undermining control.","acceptance":["At least one feedback-loop pattern documented","Pattern preserves authority while incorporating runtime learning","Risks of runaway feedback explicitly called out"],"status":"done","note":"Created docs/runtime-feedback-loops.md with 4 feedback patterns, authority preservation requirements, and 5 runaway risks with mitigations"}
{"type":"issue","epic":"EPIC-15","id":"ISSUE-15.18","title":"Define criteria for when systems or agents should bypass ConfigHub entirely","description":"Explicitly document scenarios where bypassing ConfigHub is acceptable or even desirable, to avoid accidental overreach of the authority plane.","acceptance":["Bypass criteria documented and justified","Bypass paths still include post-hoc reconciliation expectations","Document avoids framing ConfigHub as mandatory for all workflows"],"status":"done","note":"Created docs/confighub-bypass-criteria.md with 8 bypass criteria, reconciliation requirements, and explicit non-goals for ConfigHub"}
{"type":"epic","id":"EPIC-16","title":"Developer authoring experience and OAM evaluation","intent":"Decide and validate what developers author directly, ensuring they never need to reason about AWS wiring or Crossplane internals. Evaluate whether OAM provides net value as an optional authoring layer without becoming a second source of truth.","principles":["Developers author intent only","Schema constrains possibility space","Fast feedback on invalid inputs","One-way compilation","No authority leakage","Optional adoption"]}
{"type":"issue","epic":"EPIC-16","id":"ISSUE-16.1","title":"Define a minimal OAM vocabulary for serverless apps","description":"Define a small set of OAM components and traits that express application intent and required capabilities.","acceptance":["<=8 traits defined","Traits map cleanly to platform schema fields","No AWS-specific concepts in OAM"],"note":"Optional per ADR-012. OAM is a convenience layer, not required for baseline usage."}
{"type":"issue","epic":"EPIC-16","id":"ISSUE-16.2","title":"Compile OAM into the canonical platform schema","description":"Implement a one-way compiler that translates OAM configs into the canonical developer-facing config (Claim or higher-level spec).","acceptance":["Compiler produces valid canonical config","OAM cannot bypass ConfigHub authority","OAM-originated changes follow same policy and approval flow"],"note":"Optional per ADR-012. Only needed if ISSUE-16.1 is pursued."}
{"type":"issue","epic":"EPIC-16","id":"ISSUE-16.3","title":"Decide developer authoring surface (Claim vs higher-level spec)","description":"Explicitly decide whether developers will author Crossplane Claims directly or a higher-level schema that compiles into Claims.","acceptance":["Decision documented with rationale","Chosen surface aligns with platform invariants","Non-chosen option documented as future consideration"],"status":"done","note":"ADR-012 documents Claims as canonical surface, OAM as optional convenience layer."}
{"type":"issue","epic":"EPIC-16","id":"ISSUE-16.4","title":"Create canonical examples for developer-authored config","description":"Create at least two example configs (e.g., dev and prod) that represent the full developer-facing interface.","acceptance":["Examples live under a dedicated examples/ directory","Examples deploy successfully","Examples do not reference AWS-specific concepts"],"status":"done","note":"Examples exist in examples/claims/ (messagewall-dev.yaml, messagewall-prod.yaml)."}
{"type":"epic","id":"EPIC-17","title":"Production protection via ConfigHub gates","intent":"Implement concrete protections for stateful production resources using ConfigHub gates. Prevents accidental deletion or destruction of databases and other precious resources without explicit human approval.","principles":["Protect what matters most","Gates before destruction","Explicit approval for irreversible actions"],"status":"paused"}
{"type":"issue","epic":"EPIC-17","id":"ISSUE-17.1","title":"Create production ConfigHub space for the demo","description":"Create a new ConfigHub space representing the production environment (e.g., messagewall-prod) that will eventually hold the fully-rendered Crossplane manifests for prod.","acceptance":["Production space exists in ConfigHub (name documented)","Space has environment=prod metadata/tag","A placeholder or initial baseline unit can be created in the space without applying to the actuator","README/docs describe how spaces map to environments"],"status":"done","note":"Created config/prod.env, platform/argocd/application-prod.yaml, docs/confighub-spaces.md, scripts/setup-prod-space.sh. Space messagewall-prod documented with creation instructions."}
{"type":"issue","epic":"EPIC-17","id":"ISSUE-17.2","title":"Identify database units in production and mark them as precious entities","description":"Define how DynamoDB (and any other stateful data stores) are represented as units in the production space and tag/label them as precious to enable consistent protections.","acceptance":["DynamoDB unit(s) for production are present (or planned) in the prod space","Units are labeled/tagged as precious=true (or equivalent convention)","Documentation defines which resource types qualify as 'database units' vs general infrastructure","A query (documented) can list all precious database units in prod"],"status":"done","note":"Created docs/precious-resources.md defining precious convention and resource classification. Updated examples/claims/messagewall-prod.yaml with confighub.io/precious annotations. Created scripts/list-precious-units.sh for querying precious units."}
{"type":"issue","epic":"EPIC-17","id":"ISSUE-17.3","title":"Enforce delete/destroy gates on all production database units","description":"Apply ConfigHub protecting controls so that all database units in the production space cannot be deleted or destroyed without explicit override/approval.","acceptance":["All prod database units have a delete gate enabled","All prod database units have a destroy gate enabled","Attempts to delete/destroy a gated unit fail with a clear message","Gates are applied consistently (automation or documented procedure)"],"status":"paused"}
{"type":"issue","epic":"EPIC-17","id":"ISSUE-17.4","title":"Define and document the approval workflow to override delete/destroy gates","description":"Specify who can approve gated delete/destroy actions, what justification is required, how approvals are recorded, and how overrides are time/scoped-bounded.","acceptance":["Approval policy documented (roles, required approvers, audit expectations)","High-risk actions (delete/destroy in prod) require explicit human approval","Override scope is limited to a specific unit + action","Override is time-bounded or one-time-use (documented)","Process includes required justification and rollback/restore plan"],"status":"paused"}
{"type":"issue","epic":"EPIC-17","id":"ISSUE-17.5","title":"Demonstrate gated destruction request and approved execution (safe drill)","description":"Run a non-destructive or sandboxed drill that shows the end-to-end flow: attempt delete/destroy -> gate blocks -> approval granted -> action succeeds (in a safe environment or using a dummy/proxy unit).","acceptance":["A scripted demo or runbook exists showing the full gate/approval flow","Gate block is observable and recorded","Approval step is explicit and auditable","Execution step succeeds only after approval","Post-action review notes include how to reconcile state and reassert protections"],"status":"paused"}
{"type":"epic","id":"EPIC-18","title":"Tiered authority across environments","intent":"Design and document how configuration authority and gates vary by environment tier. Sandbox environments need fast iteration; production needs strict protection. Define the model that enables both without compromising either.","principles":["Strict where it matters","Fast where it's safe","Clear tier boundaries"],"status":"done"}
{"type":"issue","epic":"EPIC-18","id":"ISSUE-18.1","title":"Document limits of centralized configuration authority in high-churn environments","description":"Capture where a single authoritative configuration plane may break down under rapid experimentation, ephemeral environments, or high agent-driven change velocity.","acceptance":["ADR or doc exists describing failure modes of over-centralized authority","Examples include ephemeral stacks, throwaway environments, and agent-local loops","Document explicitly states which scenarios ConfigHub should not try to control tightly"],"status":"done","note":"Created docs/centralized-authority-limits.md with 3 failure modes, high-churn scenarios table, and explicit 'should not control' list."}
{"type":"issue","epic":"EPIC-18","id":"ISSUE-18.2","title":"Define tiered authority model across environments (sandbox vs production)","description":"Design and document a tiered authority model where sandbox and pre-production environments have relaxed gates while production remains strictly protected.","acceptance":["Authority tiers defined (e.g., sandbox, pre-prod, prod)","Each tier documents expected gate posture and approval requirements","Model supports multi-tenant use without weakening production guarantees"],"status":"done","note":"Created docs/tiered-authority-model.md with 4 tiers (sandbox/preprod/staging/prod), gate posture matrix, approval requirements by tier+risk, multi-tenant isolation, and promotion/demotion flows."}
{"type":"issue","epic":"EPIC-18","id":"ISSUE-18.3","title":"Explore time-scoped or provisional configuration for sandbox environments","description":"Investigate mechanisms for time-bound or auto-expiring configuration in sandbox environments to support fast experimentation without long-lived drift.","acceptance":["At least one proposed design for time-scoped config documented","Design includes automatic expiration or promotion semantics","Design explicitly avoids leaking provisional config into prod"],"status":"done","note":"Created docs/time-scoped-configuration.md with TTL-based design, expiration modes (delete/archive/warn), promotion flow, leakage prevention policies, and GC behavior."}
{"type":"issue","epic":"EPIC-18","id":"ISSUE-18.4","title":"Define how agents can safely operate with relaxed gates in non-prod","description":"Specify what additional freedoms agents may have in sandbox or pre-production spaces while maintaining observability and traceability.","acceptance":["Agent capabilities differ by environment tier","Sandbox allows autonomous apply within bounded schema","All agent actions remain auditable in ConfigHub"],"status":"done","note":"Created docs/agent-sandbox-freedoms.md with capability matrix by tier, ownership/identity model, audit requirements, quota enforcement, and experiment-to-production path."}
{"type":"issue","epic":"EPIC-18","id":"ISSUE-18.5","title":"Define ConfigHub's value proposition in sandbox and pre-production environments","description":"Articulate why developers and agents should still use ConfigHub when gates are relaxed, focusing on visibility, history, and coordination rather than restriction.","acceptance":["Clear value statement for non-prod usage written","Examples show benefits beyond enforcement (diffs, bulk ops, traceability)","Doc explicitly contrasts sandbox vs production value"],"status":"done","note":"Created docs/confighub-non-prod-value.md with 6 value propositions (visibility, history, bulk ops, promotion, coordination, cost), sandbox vs production comparison, and recommended posture by tier."}
{"type":"epic","id":"EPIC-19","title":"ConfigHub multi-tenancy design","intent":"Design how ConfigHub organizes configuration across environments, teams, and tenants. Clarify the relationship between ConfigHub spaces and Kubernetes namespaces, and establish conventions for multi-tenant operation.","principles":["Clear organizational model","Predictable mapping","Scalable conventions"],"status":"done"}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.1","title":"Analyze ConfigHub spaces to Kubernetes namespaces mapping","description":"Investigate whether there should be a 1:1 mapping between ConfigHub spaces and Kubernetes namespaces, or some other organizational model. Document the options and trade-offs.","acceptance":["Options for space-to-namespace mapping documented","Trade-offs of each approach enumerated","Current demo setup analyzed against each option","Recommendation made with rationale"],"status":"done","note":"Documented in ADR-013. One space per team per env; namespace = team-env."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.2","title":"Design multi-tenant organization model for ConfigHub","description":"Define how multiple teams, applications, or tenants would be organized within ConfigHub. Consider isolation, access control, and operational boundaries.","acceptance":["Multi-tenant model documented","Isolation boundaries defined","Access control patterns outlined","Model validated against 2-3 hypothetical tenant scenarios"],"status":"done","note":"ADR-013 documents space-per-team-per-env model with label-based bulk operations."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.3","title":"Document space and namespace conventions for the demo","description":"Establish and document the naming conventions and organizational patterns for ConfigHub spaces and Kubernetes namespaces in this demo project.","acceptance":["Naming conventions documented","Conventions applied to existing spaces","README or docs explain the organizational model","Conventions are consistent with multi-tenant design from ISSUE-19.2"],"status":"done","note":"Conventions documented in ADR-013 and current-focus.md."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.4","title":"Design ConfigHub space structure for multi-team workload cluster","description":"The workload cluster has 5 namespaces owned by different teams (platform-ops, data-services, customer-apps, integrations, compliance). Design how these map to ConfigHub spaces. Options: (A) One space per team, (B) One space per namespace, (C) One shared workloads space with unit-level ACLs, (D) Hierarchical spaces. Must prevent teams from editing other teams' config.","acceptance":["Options enumerated with trade-offs","Access control mechanism for each option documented","Recommendation made with rationale","ArgoCD Application strategy documented for chosen model"],"status":"done","note":"Decision: One space per team per environment (10 spaces for Order Platform). ConfigHub ACLs are space-level only (unit-level not yet available). Labels enable bulk operations across spaces. See ADR-013."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.5","title":"Separate infrastructure vs workloads in ConfigHub organization","description":"The messagewall application infrastructure (Lambda, DynamoDB, S3, IAM) exists ONLY in AWS via Crossplane - no K8s workloads. The workload cluster has microservices that are pure K8s deployments. Design how to organize these fundamentally different concerns in ConfigHub. Should infrastructure and workloads share spaces? Different space hierarchies?","acceptance":["Infrastructure vs workloads separation model documented","Relationship to environment (dev/prod) addressed","Model supports both Crossplane-managed AWS and K8s-native workloads","Clear boundary between infrastructure team and app teams"],"status":"done","note":"Decision: Infrastructure (messagewall-dev/prod) owned by messagewall team. Workloads (order-platform-*) owned by respective app teams. Demonstrates ConfigHub managing both AWS APIs (via Crossplane) and K8s APIs (via ArgoCD). See ADR-013."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.6","title":"Restructure workloads directory for Order Platform multi-tenancy","description":"Rename and restructure infra/workloads/ to represent Order Platform with 5 teams. Each team gets dev and prod namespaces. Update microservice assignments to teams.","acceptance":["Directory renamed to infra/order-platform/","Subdirectories per team: platform-ops/, data/, customer/, integrations/, compliance/","Each team has 2 microservices assigned","Namespace manifests include team and environment labels","Deployment manifests reference correct namespaces"],"status":"done","note":"Created infra/order-platform/{team}/{env}/ with 30 manifest files. Old infra/workloads/ removed."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.7","title":"Create ConfigHub spaces for Order Platform teams","description":"Create 10 ConfigHub spaces (5 teams × 2 environments) with appropriate labels for bulk operations.","acceptance":["Spaces created: order-platform-ops-dev, order-platform-ops-prod, order-data-dev, order-data-prod, order-customer-dev, order-customer-prod, order-integrations-dev, order-integrations-prod, order-compliance-dev, order-compliance-prod","All spaces have Application=order-platform label","All spaces have Team label (platform-ops, data, customer, integrations, compliance)","All spaces have Environment label (dev, prod)","Script exists to create all spaces idempotently"],"status":"done","note":"Created scripts/setup-order-platform-spaces.sh to create all 10 spaces with labels."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.8","title":"Create publish script for Order Platform multi-team structure","description":"Create script to publish Order Platform manifests to their respective ConfigHub spaces based on team ownership.","acceptance":["scripts/publish-order-platform.sh exists","Script publishes each team's manifests to correct space","Script supports --env flag for dev/prod targeting","Script supports --apply flag to make revisions live","Script supports --dry-run for preview"],"status":"done","note":"Created scripts/publish-order-platform.sh with --team, --env, --apply, --dry-run flags."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.9","title":"Create ArgoCD Applications for Order Platform teams","description":"Create ArgoCD Application manifests that sync each team's ConfigHub space to the correct namespace in the workload cluster.","acceptance":["10 ArgoCD Application manifests (one per team-env combination)","Each Application syncs from correct ConfigHub space","Each Application targets correct namespace (e.g., platform-ops-dev)","Applications use CMP plugin for ConfigHub integration","ApplicationSet considered for reducing manifest count"],"status":"done","note":"Created platform/argocd/applicationset-order-platform.yaml using ApplicationSet matrix generator."}
{"type":"issue","epic":"EPIC-19","id":"ISSUE-19.10","title":"Update demo scripts for multi-tenant Order Platform","description":"Update demo-multi-cluster.sh and related scripts to demonstrate the multi-tenant Order Platform with bulk operations across teams and environments.","acceptance":["Demo shows bulk operation targeting all dev environments","Demo shows bulk operation targeting single team across envs","Demo shows team isolation (team A cannot edit team B's config)","Demo narrative updated with Order Platform context","current-focus.md updated with new demo flow"],"status":"done","note":"Updated current-focus.md with new demo narrative and quick start guide."}
{"type":"epic","id":"EPIC-20","title":"EPIC-15 refinements and validation","intent":"Address identified gaps in EPIC-15 design documents: reduce verbosity, add diagrams, strengthen weak points, and validate against real agent behavior.","principles":["Concise over comprehensive","Diagrams over prose","Validate assumptions"],"status":"done"}
{"type":"issue","epic":"EPIC-20","id":"ISSUE-20.1","title":"Editing pass on EPIC-15 documents for concision","description":"The 8 EPIC-15 design documents are verbose. Perform an editing pass to reduce word count by 30-40% while preserving key content. Prioritize cutting redundant explanations, consolidating overlapping sections, and tightening prose.","acceptance":["Each document reduced by at least 30%","Key concepts preserved","Cross-references updated if sections consolidated","No loss of acceptance criteria coverage from original issues"],"status":"done","note":"All 8 docs reduced 30-74%. Total: ~3200 lines removed."}
{"type":"issue","epic":"EPIC-20","id":"ISSUE-20.2","title":"Add Mermaid diagrams to EPIC-15 documents","description":"Replace or supplement prose descriptions with Mermaid diagrams for: proposal lifecycle, approval workflow, risk classification decision tree, feedback loop patterns, and authority boundaries.","acceptance":["At least 5 Mermaid diagrams added across EPIC-15 docs","Diagrams render correctly in GitHub markdown","Diagrams replace or significantly reduce corresponding prose sections","Each diagram has a brief caption explaining what it shows"],"status":"done","note":"Added 6 Mermaid diagrams: proposal lifecycle, approval workflow, risk classification, feedback loops, invariant boundaries, ConfigHub bypass decision."}
{"type":"issue","epic":"EPIC-20","id":"ISSUE-20.3","title":"Strengthen MEDIUM risk auto-approve design","description":"The MEDIUM risk auto-approve with 1-hour delay may be illusory safety if operators routinely ignore notifications. Either strengthen the mechanism (e.g., require acknowledgment, shorter timeout with explicit approval) or reconsider whether MEDIUM should auto-approve at all.","acceptance":["Current weakness explicitly acknowledged in design doc","At least 2 alternative approaches evaluated","Decision made and documented with rationale","Approval-fatigue doc updated if MEDIUM behavior changes"],"status":"done","note":"Changed MEDIUM from auto-approve to require acknowledgment. 4 alternatives evaluated. Updated design-approval-gates.md, approval-fatigue-and-theater.md, design-agent-proposal-workflow.md, and risk-taxonomy.md."}
{"type":"issue","epic":"EPIC-20","id":"ISSUE-20.4","title":"Design compound change risk classification","description":"Current model uses 'highest risk wins' for multi-field changes, but this is crude. A change touching 5 LOW-risk fields might be collectively HIGH risk. Design a more nuanced approach that considers field interactions and cumulative impact.","acceptance":["Problem statement with concrete examples documented","At least 2 approaches evaluated (e.g., additive risk, interaction matrix)","Chosen approach documented with rationale","Risk taxonomy updated to reflect compound change handling"],"status":"done","note":"Added concern-based grouping + batch scope multiplier to risk-taxonomy.md. 4 approaches evaluated."}
{"type":"issue","epic":"EPIC-20","id":"ISSUE-20.5","title":"Define validation criteria for agent interaction model","description":"EPIC-15 assumes agents will propose infrastructure changes at high velocity. This assumption should be validated before heavy implementation investment. Define criteria for validating the agent interaction model and experiments to test it.","acceptance":["Key assumptions about agent behavior explicitly listed","Validation criteria defined (what would confirm or refute assumptions)","At least 2 low-cost experiments proposed to test assumptions","Decision point defined: what evidence would change the design direction"],"status":"done","note":"Created docs/agent-model-validation.md with 5 assumptions, validation criteria, 3 experiments, and decision framework."}
{"type":"issue","epic":"EPIC-20","id":"ISSUE-20.6","title":"Consolidate overlapping content across EPIC-15 documents","description":"Several concepts appear in multiple documents with slight variations (e.g., approval workflow, risk escalation). Identify overlaps, designate canonical locations, and replace duplicates with cross-references.","acceptance":["Overlap inventory created (which concepts appear where)","Canonical location designated for each overlapping concept","Duplicate content replaced with cross-references","No contradictions between documents after consolidation"],"status":"done","note":"Added canonical locations table to risk-taxonomy.md. Updated references in 4 docs to point to canonical sources."}
{"type":"epic","id":"EPIC-21","title":"Observability and control plane health","intent":"Establish observability for the configuration management platform itself. Enable operators to monitor change success rates, reconciliation latency, drift detection, and platform component health across all tenants.","principles":["Observe the platform, not just the workloads","SLOs for configuration delivery","Alert on actionable conditions only","Multi-tenant visibility with appropriate isolation"],"status":"icebox"}
{"type":"issue","epic":"EPIC-21","id":"ISSUE-21.1","title":"Define platform SLOs for configuration delivery","description":"Establish service level objectives for key platform operations: time from Claim submission to AWS resource ready, reconciliation loop latency, and drift detection coverage.","acceptance":["SLOs documented for Claim-to-Ready latency (e.g., p99 < 5 minutes)","SLOs documented for reconciliation loop frequency (e.g., every 60 seconds)","SLOs documented for drift detection coverage (e.g., 100% of managed resources checked daily)","Error budget policy defined for SLO violations","SLOs are measurable with existing or proposed metrics"],"status":"icebox"}
{"type":"issue","epic":"EPIC-21","id":"ISSUE-21.2","title":"Instrument Crossplane controllers for observability","description":"Add or expose metrics from Crossplane controllers to track reconciliation success/failure rates, latency, and resource counts per provider.","acceptance":["Prometheus metrics exposed for reconciliation success rate per provider","Metrics exposed for reconciliation latency histogram","Metrics exposed for managed resource count by type and state","Metrics are scrapeable by standard Prometheus configuration","Dashboard or queries documented to validate metrics"],"status":"icebox"}
{"type":"issue","epic":"EPIC-21","id":"ISSUE-21.3","title":"Create platform health dashboard","description":"Build a Grafana dashboard (or equivalent) showing control plane health: Crossplane controller status, ConfigHub sync status, ArgoCD sync status, and aggregate reconciliation metrics.","acceptance":["Dashboard shows Crossplane controller health (running, error states)","Dashboard shows ConfigHub-to-actuator sync latency and success rate","Dashboard shows ArgoCD application sync status","Dashboard includes tenant/environment filtering where applicable","Dashboard is importable via JSON or provisioned automatically"],"status":"icebox"}
{"type":"issue","epic":"EPIC-21","id":"ISSUE-21.4","title":"Implement actionable alerting for platform failures","description":"Define alerts for platform-level failures that require operator intervention: controller crashloops, persistent reconciliation failures, ConfigHub unreachable, stuck syncs.","acceptance":["Alert defined for Crossplane controller pod restarts exceeding threshold","Alert defined for reconciliation failures persisting beyond SLO window","Alert defined for ConfigHub connectivity failures","Alert defined for ArgoCD sync stuck in progressing state","Alerts include runbook links or remediation guidance","Alert routing to appropriate channel documented"],"status":"icebox"}
{"type":"issue","epic":"EPIC-21","id":"ISSUE-21.5","title":"Add tenant-scoped observability views","description":"Enable per-tenant visibility into their own Claims, resources, and reconciliation status without exposing other tenants' data.","acceptance":["Tenant can view only their own Claims and resources","Metrics can be filtered/aggregated by tenant label","Dashboard supports tenant-scoped views","Access control documented for tenant-scoped queries","Multi-tenant isolation validated with test scenarios"],"status":"icebox"}
{"type":"epic","id":"EPIC-22","title":"Cost management and FinOps","intent":"Enable cost attribution, budget enforcement, and chargeback/showback for cloud resources provisioned through the platform. Ensure costs flow from Claims to AWS resources with full traceability.","principles":["Cost follows the Claim","Budgets prevent surprise bills","Visibility before enforcement","Team-level accountability"],"status":"icebox"}
{"type":"issue","epic":"EPIC-22","id":"ISSUE-22.1","title":"Define cost attribution tagging strategy","description":"Establish a tagging convention that links AWS resource costs back to Claims, tenants, and environments. Tags must be applied automatically and consistently across all provisioned resources.","acceptance":["Tagging schema documented (e.g., claim-id, tenant, environment, cost-center)","Tags applied automatically via Kyverno mutation or Composition","All AWS resource types support required tags","Tag propagation verified for nested resources (e.g., Lambda execution role)","Tags align with AWS Cost Allocation Tags requirements"],"status":"icebox"}
{"type":"issue","epic":"EPIC-22","id":"ISSUE-22.2","title":"Implement cost aggregation and reporting by tenant","description":"Create a mechanism to aggregate AWS costs by tenant using the attribution tags. Reports should show cost breakdown by environment, resource type, and time period.","acceptance":["Cost data aggregated by tenant and environment","Report shows cost breakdown by AWS service type","Report supports daily, weekly, and monthly aggregation","Cost data retrievable via API or dashboard","Historical cost trends visible for at least 30 days"],"status":"icebox"}
{"type":"issue","epic":"EPIC-22","id":"ISSUE-22.3","title":"Implement budget alerts for tenants","description":"Allow tenants to define spending budgets with alerts when thresholds are approached or exceeded. Budgets should be configurable per tenant and environment.","acceptance":["Tenant can set monthly budget threshold","Alerts triggered at 50%, 80%, and 100% of budget","Alert notifications delivered to tenant-specified channel","Budget configuration stored in ConfigHub or documented location","Budget status visible in tenant dashboard or API"],"status":"icebox"}
{"type":"issue","epic":"EPIC-22","id":"ISSUE-22.4","title":"Design chargeback/showback model for platform usage","description":"Document how costs will be attributed and communicated to tenants. Define whether the model is showback (visibility only) or chargeback (actual billing), and how shared platform costs are allocated.","acceptance":["Chargeback vs showback decision documented with rationale","Shared/platform cost allocation method defined (e.g., proportional, flat fee)","Cost report format documented with example","Integration with enterprise finance systems outlined","Model validated against 2-3 tenant scenarios"],"status":"icebox"}
{"type":"epic","id":"EPIC-23","title":"Disaster recovery and business continuity","intent":"Design recovery procedures for platform components and configuration state. Ensure the platform can recover from regional failures, data loss, and component unavailability without losing configuration history.","principles":["Configuration state is precious","Recovery procedures must be tested","RPO and RTO explicitly defined","Actuator clusters are replaceable, authority is not"],"status":"icebox"}
{"type":"issue","epic":"EPIC-23","id":"ISSUE-23.1","title":"Define RPO and RTO for platform components","description":"Establish recovery point objectives (maximum data loss) and recovery time objectives (maximum downtime) for each platform component: ConfigHub, actuator cluster, ArgoCD, and AWS resources.","acceptance":["RPO defined for ConfigHub (configuration state)","RPO defined for actuator cluster state","RTO defined for full platform recovery","RTO defined for partial recovery (single component)","Objectives aligned with business requirements and documented"],"status":"icebox"}
{"type":"issue","epic":"EPIC-23","id":"ISSUE-23.2","title":"Implement ConfigHub state backup strategy","description":"Design and implement backup procedures for ConfigHub configuration state including revision history. Backups must support point-in-time recovery within RPO.","acceptance":["Automated backup schedule documented and implemented","Backup includes full configuration state and revision history","Backup stored in separate region or storage account","Backup retention policy defined (e.g., 30 days)","Restore procedure documented and tested"],"status":"icebox"}
{"type":"issue","epic":"EPIC-23","id":"ISSUE-23.3","title":"Document actuator cluster recovery procedure","description":"Create runbook for recovering or replacing an actuator cluster. Procedure should restore Crossplane, ArgoCD, and re-sync all managed resources from ConfigHub.","acceptance":["Runbook documents cluster recreation from scratch","Procedure restores Crossplane with correct providers and ProviderConfig","Procedure reconnects to ConfigHub and re-syncs configuration","Procedure verifies AWS resources are adopted (not recreated)","Estimated recovery time documented and validated"],"status":"icebox"}
{"type":"issue","epic":"EPIC-23","id":"ISSUE-23.4","title":"Implement DR test procedure and schedule","description":"Create a periodic disaster recovery test that validates backup integrity and recovery procedures without impacting production.","acceptance":["DR test procedure documented","Test validates ConfigHub backup restore","Test validates actuator cluster recovery","Test runs in isolated environment (no prod impact)","DR test schedule defined (e.g., quarterly)","Test results documented with pass/fail criteria"],"status":"icebox"}
{"type":"issue","epic":"EPIC-23","id":"ISSUE-23.5","title":"Design regional failover strategy for ConfigHub","description":"Document how ConfigHub authority would transfer to a secondary region if the primary becomes unavailable. Address data consistency, DNS failover, and client redirection.","acceptance":["Failover trigger criteria defined","Data replication strategy documented (sync vs async)","DNS or client failover mechanism specified","Consistency guarantees during failover documented","Failback procedure documented"],"status":"icebox"}
{"type":"epic","id":"EPIC-24","title":"Federation and multi-cluster operations","intent":"Extend the platform to manage resources across multiple actuator clusters, regions, and potentially cloud providers. Define how ConfigHub authority scales to many clusters without becoming a bottleneck.","principles":["Authority remains centralized, actuation is distributed","Regional autonomy for latency-sensitive operations","Consistent policy enforcement across clusters","Graceful degradation when clusters are unreachable"],"status":"icebox"}
{"type":"issue","epic":"EPIC-24","id":"ISSUE-24.1","title":"Design multi-cluster architecture model","description":"Document how multiple actuator clusters relate to ConfigHub authority. Define whether clusters are peers, regional replicas, or environment-specific (dev/staging/prod clusters).","acceptance":["Multi-cluster topology options documented","Recommended model for this demo chosen with rationale","Cluster-to-ConfigHub relationship defined","Cross-cluster resource dependencies addressed","Model supports adding clusters without architectural changes"],"status":"icebox"}
{"type":"issue","epic":"EPIC-24","id":"ISSUE-24.2","title":"Implement cluster registration and discovery","description":"Create a mechanism for actuator clusters to register with the platform and for ConfigHub to discover available clusters for targeting.","acceptance":["Cluster registration procedure documented","Cluster metadata captured (region, environment, capabilities)","ConfigHub can query available clusters","Cluster health status tracked","Unregistration/decommission procedure documented"],"status":"icebox"}
{"type":"issue","epic":"EPIC-24","id":"ISSUE-24.3","title":"Extend ConfigHub targeting to multiple clusters","description":"Enable ConfigHub to target configuration to specific clusters based on labels, regions, or explicit selection.","acceptance":["Configuration can target a specific cluster by name","Configuration can target clusters by label selector","Same Claim can deploy to multiple clusters (multi-target)","Targeting syntax documented with examples","Targeting errors surface clearly in ConfigHub"],"status":"icebox"}
{"type":"issue","epic":"EPIC-24","id":"ISSUE-24.4","title":"Implement cross-cluster policy consistency","description":"Ensure policies defined centrally are enforced consistently across all actuator clusters. Handle policy version drift and update propagation.","acceptance":["Policies distributed to all registered clusters","Policy version tracked per cluster","Policy update propagation latency measurable","Clusters with outdated policies are flagged","Policy enforcement is consistent regardless of target cluster"],"status":"icebox"}
{"type":"issue","epic":"EPIC-24","id":"ISSUE-24.5","title":"Design graceful degradation for unreachable clusters","description":"Define platform behavior when an actuator cluster becomes unreachable. Address queued changes, status reporting, and reconnection handling.","acceptance":["Unreachable cluster detection criteria defined","Pending changes queued during outage (if applicable)","Status clearly indicates cluster unreachable vs apply failed","Reconnection triggers pending change application","Prolonged outage escalation procedure documented"],"status":"icebox"}
{"type":"epic","id":"EPIC-25","title":"Secrets and credential management","intent":"Integrate external secrets management for sensitive configuration. Ensure credentials are never stored in ConfigHub or Git, rotation is automated, and access is scoped per tenant.","principles":["Secrets never in Git or ConfigHub","Zero standing privilege where possible","Rotation is automated, not manual","Audit trail for all secret access"],"status":"icebox"}
{"type":"issue","epic":"EPIC-25","id":"ISSUE-25.1","title":"Select and integrate external secrets operator","description":"Choose an external secrets solution (e.g., External Secrets Operator, Vault) and integrate it with the actuator cluster to inject secrets into Crossplane-managed resources.","acceptance":["Secrets operator selected with rationale documented","Operator installed in actuator cluster","Secrets can be referenced from Claims without embedding values","Integration tested with at least one AWS credential scenario","Installation is idempotent and documented"],"status":"icebox"}
{"type":"issue","epic":"EPIC-25","id":"ISSUE-25.2","title":"Define secrets scoping model for multi-tenant access","description":"Design how secrets are organized and access-controlled so tenants can only access their own secrets. Prevent cross-tenant secret leakage.","acceptance":["Secrets namespace/path convention documented","Tenant can only access secrets in their scope","Cross-tenant access explicitly denied","Scoping model validated with test scenarios","Model supports shared platform secrets (e.g., Crossplane provider credentials)"],"status":"icebox"}
{"type":"issue","epic":"EPIC-25","id":"ISSUE-25.3","title":"Implement automated credential rotation","description":"Create a mechanism for automatic rotation of credentials used by the platform (e.g., Crossplane AWS credentials, database passwords) without manual intervention.","acceptance":["Rotation schedule configurable per secret type","Rotation occurs without service interruption","Old credentials revoked after grace period","Rotation events logged for audit","Rotation failure triggers alert"],"status":"icebox"}
{"type":"issue","epic":"EPIC-25","id":"ISSUE-25.4","title":"Implement secret access auditing","description":"Ensure all access to secrets is logged with sufficient detail for security audit and compliance.","acceptance":["Secret read events logged with accessor identity","Secret write/update events logged","Audit logs include timestamp, secret path, and action","Logs exportable to SIEM or compliance system","Audit log retention policy defined"],"status":"icebox"}
{"type":"issue","epic":"EPIC-25","id":"ISSUE-25.5","title":"Document secrets workflow for developers","description":"Create developer documentation explaining how to use secrets in Claims without exposing sensitive values. Include examples for common scenarios (database passwords, API keys).","acceptance":["Documentation explains secrets reference syntax in Claims","Example provided for database password injection","Example provided for external API key usage","Troubleshooting section for common secrets errors","Documentation lives alongside Claim schema docs"],"status":"icebox"}
{"type":"epic","id":"EPIC-26","title":"Change velocity controls and rollback orchestration","intent":"Implement controls that limit blast radius of configuration changes and enable coordinated rollback when changes cause harm. Support canary deployments, change freezes, and automatic rollback on health degradation.","principles":["Limit blast radius by default","Rollback is always possible","Health signals trigger automatic response","Change freezes are enforceable"],"status":"icebox"}
{"type":"epic","id":"EPIC-27","title":"Service catalog and discoverability","intent":"Provide a catalog of available platform products (XRDs, Claims) so teams can discover what's available, understand schemas, and provision resources through self-service. Include versioning, deprecation notices, and migration guides.","principles":["Discoverable beats documented","Schema is the source of truth","Deprecation is communicated early","Examples for every product"],"status":"icebox"}
{"type":"epic","id":"EPIC-28","title":"Self-service tenant onboarding","intent":"Automate the provisioning of new teams and divisions onto the platform. A single onboarding action should create ConfigHub spaces, Kubernetes namespaces, IAM boundaries, initial quotas, and baseline policies.","principles":["Onboarding is one action, not twenty","Secure by default","Quotas from day one","Offboarding cleans up completely"],"status":"icebox"}
{"type":"epic","id":"EPIC-29","title":"Enterprise identity and access integration","intent":"Integrate with enterprise identity providers for authentication and authorization. Define role hierarchies, approval workflow integration with identity, and compliance reporting for auditors.","principles":["SSO everywhere","Roles map to real organizational structure","Approvals are traceable to identities","Audit artifacts are exportable"],"status":"icebox"}
{"type":"epic","id":"EPIC-30","title":"Drift detection and continuous reconciliation","intent":"Formalize how drift between desired state (ConfigHub) and actual state (AWS) is detected, reported, and remediated. Define policies for when to auto-remediate vs alert vs accept drift.","principles":["Drift is detected, not ignored","Not all drift requires remediation","Out-of-band changes are captured","Trending reveals systemic issues"],"status":"icebox"}
{"type":"epic","id":"EPIC-31","title":"Schema lifecycle and migration","intent":"Define how platform schemas (XRDs) evolve over time. Establish versioning strategy, backward compatibility guarantees, migration automation, and deprecation timelines.","principles":["Schema changes are planned, not reactive","Migrations are automated where possible","Deprecation has a timeline","Breaking changes require migration path"],"status":"icebox"}
{"type":"epic","id":"EPIC-32","title":"Control plane performance and scalability","intent":"Ensure the platform scales to thousands of Claims across hundreds of teams. Benchmark ConfigHub, Crossplane, and ArgoCD under load. Define scaling strategies and performance acceptance criteria.","principles":["Measure before optimizing","Scaling is horizontal where possible","Performance budgets are explicit","Degradation is graceful"],"status":"icebox"}
{"type":"epic","id":"EPIC-33","title":"Testing and preview environments","intent":"Enable infrastructure change testing through preview environments, PR-based previews, and integration test harnesses. Support chaos engineering for platform resilience validation.","principles":["Test infrastructure like code","Preview before merge","Chaos reveals weaknesses","Staging mirrors production topology"],"status":"icebox"}
{"type":"epic","id":"EPIC-34","title":"Network and connectivity patterns","intent":"Define patterns for VPC provisioning, cross-account networking, private endpoints, and service mesh integration. Establish templates that teams can use without deep networking expertise.","principles":["Networking is a platform concern","Templates over custom configs","Security groups are restrictive by default","Connectivity is documented"],"status":"icebox"}
{"type":"epic","id":"EPIC-35","title":"Agent operational boundaries","intent":"Define identity, rate limits, quotas, and monitoring for AI agents operating on the platform. Establish procedures for agent credential rotation, anomaly detection, and emergency suspension.","principles":["Agents have explicit identity","Rate limits prevent runaway automation","Anomalies trigger alerts, not just logs","Suspension is immediate when needed"],"status":"icebox"}
{"type":"epic","id":"EPIC-36","title":"Workload cluster with observable microservices","intent":"Add a second Kubernetes cluster running 10 tiny microservices that generate sparse, readable logs. Demonstrates ConfigHub managing multiple actuators - infrastructure (Crossplane) and workloads (microservices) from a single authority. Makes the demo visually compelling with distinct pod names and observable activity in kubectl.","principles":["ConfigHub is authority for all clusters","Microservices are minimal and observable","Distinct names for visual clarity","Sparse logs (not noisy)"],"status":"in_progress"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.1","title":"Create workload cluster bootstrap script","description":"Create a second kind cluster named 'workload' alongside the existing 'actuator' cluster. Script should be idempotent and follow the pattern of bootstrap-kind.sh.","acceptance":["scripts/bootstrap-workload-cluster.sh exists","Cluster named 'workload' created via kind","Script is idempotent (safe to re-run)","Both clusters accessible via kubectl context switching"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.2","title":"Install ArgoCD on workload cluster syncing from ConfigHub","description":"Install ArgoCD on the workload cluster configured to sync microservice deployments from a ConfigHub space (e.g., messagewall-workloads). Uses the same CMP plugin pattern as the actuator cluster.","acceptance":["ArgoCD running in workload cluster","CMP plugin configured for ConfigHub","ArgoCD Application targets the workload ConfigHub space","Sync status observable in ArgoCD UI"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.3","title":"Design 10 microservices with distinct names and log patterns","description":"Define 10 microservices with memorable, distinct names and unique log message patterns. Each service logs a short message every 30-60 seconds. Names should be immediately recognizable in kubectl output.","acceptance":["10 service names defined","Each service has a unique log message pattern","Log frequency is sparse (30-60s intervals)","Names are short, memorable, and distinct","Design documented in docs/ or README"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.4","title":"Create single configurable container image for microservices","description":"Build one minimal container image that can be configured via environment variables to behave as any of the 10 microservices. Avoids maintaining 10 separate images.","acceptance":["Single Dockerfile produces the image","SERVICE_NAME env var determines behavior","LOG_INTERVAL env var controls frequency","Image is minimal (alpine or distroless base)","Image published or buildable locally"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.5","title":"Create Kubernetes manifests for 10 microservices","description":"Create deployment manifests for all 10 microservices. Each deployment uses the same image with different configuration. Manifests should be suitable for ConfigHub storage.","acceptance":["10 Deployment manifests exist","Each uses the common image with SERVICE_NAME configured","Manifests are in infra/workloads/ or similar","Resource requests are minimal (demo-sized)","Labels include service name for easy filtering"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.6","title":"Publish microservice manifests to ConfigHub","description":"Create a ConfigHub space for workload configuration and publish the microservice manifests. Wire up CI or script to keep ConfigHub in sync.","acceptance":["ConfigHub space exists (e.g., messagewall-workloads)","All 10 microservice manifests stored as units","Manifests sync to workload cluster via ArgoCD","Changes to manifests flow through ConfigHub"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.7","title":"Create demo script showing multi-cluster ConfigHub management","description":"Create a demo script that shows ConfigHub managing both clusters: infrastructure changes to actuator cluster, workload changes to workload cluster. Includes kubectl commands to observe both.","acceptance":["scripts/demo-multi-cluster.sh exists","Demo shows ConfigHub bulk change affecting workload cluster","Demo shows kubectl logs from multiple microservices","Demo shows ArgoCD sync status for both clusters","Demo narrative documented with talking points"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.8","title":"Create Crossplane reconciliation demo (delete Lambda, watch recreation)","description":"Create a demo script that shows Crossplane's self-healing by deleting an AWS resource directly (e.g., Lambda function via AWS CLI) and observing Crossplane detect drift and recreate it. Visual proof that the desired state in ConfigHub is continuously enforced.","acceptance":["scripts/demo-reconciliation.sh exists","Script deletes a Lambda function via AWS CLI","Script shows Crossplane detecting the drift","Script shows Crossplane recreating the resource","Timing/polling shows the reconciliation loop in action","Demo includes talking points about GitOps and desired state"],"status":"done"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.9","title":"Create bulk change demo: update Lambda timeout via ConfigHub","description":"Demo script showing bulk configuration change across multiple Lambdas. Change timeout from 10s to 30s on all Lambda functions, publish to ConfigHub, watch ArgoCD sync and Crossplane update AWS.","acceptance":["scripts/demo-bulk-timeout.sh exists","Script updates Lambda timeout in manifests","Script publishes changes to ConfigHub","Script shows ArgoCD sync status","Script verifies new timeout in AWS","Demo includes talking points about bulk operations"],"status":"pending"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.10","title":"Create bulk change demo: add tag to all Crossplane resources","description":"Demo script showing how to add a new tag (e.g., cost-center=platform-team) to all AWS resources managed by Crossplane. Publish to ConfigHub, watch rollout across Lambda, DynamoDB, S3, IAM.","acceptance":["scripts/demo-bulk-tags.sh exists","Script adds new tag to all resource manifests","Script publishes all changes to ConfigHub","Script shows Crossplane updating resources","Script verifies tags in AWS across resource types","Demo includes talking points about governance and cost attribution"],"status":"pending"}
{"type":"issue","epic":"EPIC-36","id":"ISSUE-36.11","title":"Create iTerm2 demo layout script","description":"AppleScript or shell script that opens iTerm2 with a multi-pane layout for the demo. Panes show: (1) actuator managed resources watch, (2) workload pods watch, (3) microservice logs, (4) command pane for running demo. Each pane has a badge/title for clarity.","acceptance":["scripts/demo-iterm-layout.sh or .scpt exists","Opens iTerm2 with 5-6 labeled panes","Panes auto-run watch commands on start","Badge or tab title identifies each pane","Works on fresh terminal launch","README documents how to use it"],"status":"pending"}
{"type":"epic","id":"EPIC-37","title":"Bootstrap process improvements","intent":"Reduce friction in the bootstrap process by adding better error handling, prerequisite checks, and automatic credential setup. Make teardown-rebuild cycles smooth and reliable.","principles":["Fail fast with clear errors","Automate credential setup where possible","Scripts should be idempotent","Check prerequisites before proceeding"],"status":"done"}
{"type":"issue","epic":"EPIC-37","id":"ISSUE-37.1","title":"Auto-create AWS credentials secret from aws cli config","description":"The bootstrap-aws-providers.sh script fails if the aws-credentials secret doesn't exist. Add automatic creation of the secret from the user's aws cli configuration if the secret is missing.","acceptance":["Script checks if aws-credentials secret exists","If missing, creates it from aws configure output","Validates AWS credentials are configured before attempting","Clear error message if aws cli not configured","Works on fresh cluster with no manual steps"],"status":"done","note":"Updated bootstrap-aws-providers.sh to auto-create secret from aws configure"}
{"type":"issue","epic":"EPIC-37","id":"ISSUE-37.2","title":"Handle provider timeout gracefully in bootstrap-aws-providers.sh","description":"When S3 provider times out waiting for healthy status, the script exits early and doesn't apply ProviderConfig. Script should continue with other providers and apply ProviderConfig even if one provider is slow.","acceptance":["Script continues even if one provider times out","ProviderConfig is always applied if providers are installed","Final status check shows which providers are healthy","Warns but doesn't fail if a provider is still initializing","Increases default timeout or adds retry logic"],"status":"done","note":"Script now continues on timeout, always applies ProviderConfig, shows final health status"}
{"type":"issue","epic":"EPIC-37","id":"ISSUE-37.3","title":"Add ConfigHub auth check to scripts that use cub CLI","description":"Scripts like setup-argocd-confighub-auth.sh and setup-order-platform-spaces.sh fail cryptically if ConfigHub credentials are expired. Add an auth check at the start of these scripts.","acceptance":["Scripts check cub auth status before proceeding","If auth is expired/invalid, prompt user to run cub auth login","Clear error message explaining the issue","Auth check is fast (doesn't slow down scripts when valid)","Consider adding cub auth login --non-interactive option if available"],"status":"done","note":"Added auth check via cub space list to setup-argocd-confighub-auth.sh, setup-workload-confighub-auth.sh, setup-order-platform-spaces.sh"}
{"type":"issue","epic":"EPIC-37","id":"ISSUE-37.4","title":"Reorder bootstrap to create ConfigHub spaces before workers","description":"The setup-argocd-confighub-auth.sh script tries to create a worker in a space that doesn't exist yet. The bootstrap sequence should create spaces first, then workers.","acceptance":["Document correct bootstrap order in current-focus.md","Auth scripts check if required space exists first","If space doesn't exist, provide clear error with fix command","Consider having auth scripts auto-create the space if missing","Update quick start guide with correct order"],"status":"done","note":"Updated current-focus.md with correct order, added space existence checks to auth scripts"}
{"type":"epic","id":"EPIC-38","title":"Demo friction fixes","intent":"Address friction points discovered during demo walkthrough that prevent smooth teardown-rebuild cycles and cause confusion during demos.","principles":["Scripts work on fresh clusters","Context switches are explicit","Documentation matches reality","One command deploys messagewall"],"status":"pending"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.1","title":"Fix install-xrd.sh to specify kubectl context","description":"The install-xrd.sh script fails when kubectl's current context is not kind-actuator. Add --context kind-actuator to all kubectl commands and use fully-qualified resource names for kubectl wait (function.pkg.crossplane.io vs function.lambda.aws.upbound.io).","acceptance":["Script works regardless of current kubectl context","All kubectl commands use --context kind-actuator","kubectl wait uses fully-qualified resource names","Script succeeds on fresh cluster after bootstrap"],"status":"done"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.2","title":"Create deploy-messagewall.sh script","description":"Create a single script that deploys the messagewall infrastructure end-to-end. Handles XRD installation, Lambda artifact building/uploading, and Claim application. Referenced by demo-reconciliation.sh and DEMO-RUNBOOK.md.","acceptance":["scripts/deploy-messagewall.sh exists","Script installs XRD/Composition if not present","Script builds Lambda artifacts if not present","Script uploads artifacts to S3 bucket (creates bucket first if needed)","Script applies the messagewall-dev Claim","Script waits for all resources to reach Ready state","Script outputs the API endpoint and website URL"],"status":"done"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.3","title":"Update DEMO-RUNBOOK.md for Order Platform structure","description":"DEMO-RUNBOOK.md references outdated namespace (-n microservices) and directory (infra/workloads/) structure. Update to reflect the Order Platform multi-tenancy model.","acceptance":["Replace -n microservices with team-specific namespaces (e.g., platform-ops-dev)","Replace infra/workloads/ references with infra/order-platform/","Update kubectl commands to use correct namespaces","Update emergency recovery commands","Verify all commands in runbook work on current setup"],"status":"done"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.4","title":"Update demo-iterm-layout.sh for Order Platform namespaces","description":"The iTerm layout script uses -n microservices namespace which no longer exists. Update to use team-specific namespaces like platform-ops-dev.","acceptance":["WORKLOAD pane uses correct namespace","HEARTBEAT pane uses platform-ops-dev namespace","COUNTER pane uses data-dev namespace","Script works on fresh cluster after bootstrap","Layout diagram in script matches actual panes"],"status":"done"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.5","title":"Create messagewall-prod ConfigHub space","description":"Only messagewall-dev ConfigHub space exists. Create messagewall-prod space to match the documented 12-space structure in current-focus.md.","acceptance":["messagewall-prod space exists in ConfigHub","Space has Environment=prod label","Space has Application=messagewall label","scripts/setup-order-platform-spaces.sh or similar creates it","cub space list shows messagewall-prod"],"status":"pending"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.6","title":"Migrate XRD from v1 to v2","description":"Crossplane shows deprecation warning: 'CompositeResourceDefinition v1 is deprecated and will be removed in a future release'. Migrate XRD to v2 schema.","acceptance":["XRD uses apiextensions.crossplane.io/v2","No deprecation warnings on kubectl apply","Existing Claims continue to work","Documentation updated if schema changes"],"status":"pending"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.7","title":"Add reconciliation trigger to demo-reconciliation.sh","description":"Crossplane doesn't immediately detect drift when a Lambda is deleted directly in AWS. The demo script should trigger a reconciliation (via annotation or provider restart) to speed up detection.","acceptance":["Script annotates resource or restarts provider after deletion","Drift detection happens within 30 seconds of deletion","Script explains why the trigger is needed","Demo still shows the self-healing concept effectively"],"status":"pending"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.8","title":"Fix teardown to delete Crossplane Claims before clusters","description":"The teardown script deletes kind clusters while Crossplane resources still exist, orphaning AWS resources. The script waits 5 minutes for Crossplane to delete resources, but the Claim was never deleted. Must delete Claims/XRs explicitly before deleting clusters.","acceptance":["Script deletes ServerlessEventAppClaims before waiting for AWS cleanup","Script deletes any CompositeResources that aren't managed by ArgoCD","AWS resources are deleted by Crossplane before clusters are destroyed","No orphaned AWS resources after teardown","Script handles case where Claim doesn't exist gracefully"],"status":"done"}
{"type":"issue","epic":"EPIC-38","id":"ISSUE-38.9","title":"Add force-cleanup option for orphaned AWS resources","description":"When teardown fails to delete AWS resources (e.g., clusters deleted too early), provide a way to clean up orphaned resources directly via AWS CLI.","acceptance":["scripts/cleanup-aws-orphans.sh exists or teardown has --force-aws flag","Script deletes messagewall-* Lambda, DynamoDB, S3, IAM, EventBridge resources","Script handles deletion order dependencies (policies before roles, etc.)","Script is idempotent (safe to run multiple times)","Script confirms what will be deleted before proceeding"],"status":"done"}
{"type":"note","id":"NOTE-2026-01-29","title":"ArgoCD CMP debugging session fixes","description":"Session discovered several issues with ArgoCD CMP + ConfigHub integration: (1) ArgoCD passes Application env vars with ARGOCD_ENV_ prefix - fixed in cmp-plugin.yaml; (2) ConfigHub workers need --org-role admin for cross-space read access; (3) Hardcoded CONFIGHUB_SPACE in values-workload.yaml was overriding Application values - removed; (4) Must use HeadRevisionNum not LiveRevisionNum for pull-based sync. All fixes documented in beads/current-focus.md 'Known Issues & Fixes' section.","date":"2026-01-29"}
{"type":"epic","id":"EPIC-39","title":"ConfigHub Triggers demo","intent":"Demonstrate ConfigHub Triggers as validating/mutating admission controllers for configuration. Show how OPA policies can block non-compliant config before it reaches the cluster, complementing Kyverno's runtime enforcement.","principles":["Policy enforcement at config authority layer","Fail fast before actuation","Triggers complement Kyverno (defense in depth)","Visual demo of blocked vs allowed changes"],"status":"pending"}
{"type":"issue","epic":"EPIC-39","id":"ISSUE-39.1","title":"Create validation trigger for Lambda memory minimum","description":"Create a ConfigHub trigger using vet-celexpr or OPA that validates Lambda functions have memorySize >= 256MB for production workloads. Demonstrates blocking non-compliant config at the ConfigHub layer.","acceptance":["Trigger created in messagewall-dev space","Attempting to set memory < 256 creates an apply gate","Clear error message explains the violation","Demo script shows the blocked change"],"status":"pending"}
{"type":"issue","epic":"EPIC-39","id":"ISSUE-39.2","title":"Create mutation trigger for default tags","description":"Create a ConfigHub trigger that automatically adds default tags to resources missing them, similar to Kyverno but at the config authority layer. Shows mutation capability.","acceptance":["Trigger adds missing tags on unit update","Tags include source=confighub-trigger","Demonstrates mutation before Kyverno sees the resource"],"status":"pending"}
{"type":"issue","epic":"EPIC-39","id":"ISSUE-39.3","title":"Add Triggers section to demo script","description":"Add Part 6 to demo-script.md showing Triggers in action. Include both validation (blocked change) and mutation (auto-added fields) examples.","acceptance":["Demo script has Triggers section","Shows validation failure with apply gate","Shows successful change after fix","Explains defense-in-depth with Kyverno"],"status":"pending"}
{"type":"epic","id":"EPIC-40","title":"Multi-region AWS deployment demo","intent":"Demonstrate multi-region architecture with separate actuator clusters per region, each syncing from ConfigHub and managing regional AWS resources independently.","principles":["One actuator cluster per region","ConfigHub as single authority across regions","Regional blast radius isolation","Bulk operations via ConfigHub push to multiple spaces"],"status":"pending"}
{"type":"issue","epic":"EPIC-40","id":"ISSUE-40.1","title":"Create bootstrap script for regional actuator clusters","description":"Extend bootstrap-kind.sh to support creating multiple named clusters (actuator-east, actuator-west). Each cluster gets full Crossplane + ArgoCD + Kyverno stack.","acceptance":["bootstrap-kind.sh accepts --name and --region flags","Can create actuator-east and actuator-west clusters independently","kubectl contexts named kind-actuator-east and kind-actuator-west"],"status":"pending"}
{"type":"issue","epic":"EPIC-40","id":"ISSUE-40.2","title":"Create regional ProviderConfigs for Crossplane","description":"Each regional actuator cluster gets a ProviderConfig for its region. actuator-east uses us-east-1, actuator-west uses us-west-2.","acceptance":["actuator-east cluster has ProviderConfig for us-east-1","actuator-west cluster has ProviderConfig for us-west-2","Same IAM credentials work for both regions"],"status":"pending"}
{"type":"issue","epic":"EPIC-40","id":"ISSUE-40.3","title":"Create regional ConfigHub spaces and ArgoCD auth","description":"Create messagewall-dev-east and messagewall-dev-west spaces with Region labels. Each actuator cluster gets its own ConfigHub worker and ArgoCD credentials.","acceptance":["messagewall-dev-east space with Region=us-east-1 label","messagewall-dev-west space with Region=us-west-2 label","Each cluster has confighub-actuator-credentials secret","ArgoCD CMP syncs from correct regional space"],"status":"pending"}
{"type":"issue","epic":"EPIC-40","id":"ISSUE-40.4","title":"Create regional infrastructure manifests","description":"Duplicate messagewall infrastructure for each region with appropriate naming (messagewall-east-*, messagewall-west-*). Publish to respective ConfigHub spaces.","acceptance":["infra/messagewall-east/ and infra/messagewall-west/ directories","Resources use region-specific naming conventions","publish-messagewall.sh supports --region flag"],"status":"pending"}
{"type":"issue","epic":"EPIC-40","id":"ISSUE-40.5","title":"Create cross-region bulk update demo script","description":"Script that pushes a configuration change (e.g., Lambda timeout) to both regional spaces simultaneously. Shows ConfigHub as single authority for multi-region.","acceptance":["demo-multiregion-update.sh updates both spaces","Changes reconcile in both AWS regions","Demo narrative shows single command affecting multiple regions"],"status":"pending"}
{"type":"issue","epic":"EPIC-40","id":"ISSUE-40.6","title":"Update demo guide with multi-region architecture","description":"Document the multi-region setup, teardown, and demo flow. Include architecture diagram and talking points.","acceptance":["docs/demo-guide.md includes multi-region section","beads/current-focus.md updated with multi-region quick start","Architecture diagram shows both clusters"],"status":"pending"}
